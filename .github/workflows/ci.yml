name: CI Checks

# CI pipeline for Scry API: linting, unit tests, integration tests, and building
# Includes optional Gemini API integration testing via workflow dispatch or weekly schedule

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]
  workflow_dispatch:
    inputs:
      run-gemini-tests:
        description: 'Run Gemini API integration tests'
        type: boolean
        default: true
        required: true
  schedule:
    - cron: '0 2 * * 1' # Weekly on Monday at 2:00 AM UTC
env:
  GO_VERSION: '1.24'

permissions:
  contents: read # Default permission

jobs:
  pre-flight:
    name: Pre-flight Checks
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: scry_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true
      - name: Install required tools and libraries for CGo
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client gcc libpq-dev

      - name: Build main application
        run: go build ./cmd/server

      - name: Run CI pre-flight checks
        run: |
          chmod +x ./scripts/ci-pre-flight.sh
          ./scripts/ci-pre-flight.sh
        env:
          # Enable CGo
          CGO_ENABLED: 1
          # Database environment
          DATABASE_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          SCRY_TEST_DB_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          SCRY_DATABASE_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          # Project root variable
          SCRY_PROJECT_ROOT: ${{ github.workspace }}
          # Other required environment variables
          SCRY_AUTH_JWT_SECRET: ci-test-jwt-secret-32-characters-long
          SCRY_AUTH_BCRYPT_COST: "10"
          SCRY_AUTH_TOKEN_LIFETIME_MINUTES: "60"
          SCRY_AUTH_REFRESH_TOKEN_LIFETIME_MINUTES: "10080"
          SCRY_LLM_GEMINI_API_KEY: ci-test-gemini-key
          SCRY_LLM_MODEL_NAME: gemini-2.0-flash
          SCRY_LLM_PROMPT_TEMPLATE_PATH: prompts/flashcard_template.txt
          SCRY_LLM_MAX_RETRIES: "3"
          SCRY_LLM_RETRY_DELAY_SECONDS: "2"
          SCRY_SERVER_PORT: "8080"
          SCRY_SERVER_LOG_LEVEL: info
          SCRY_TASK_WORKER_COUNT: "2"
          SCRY_TASK_QUEUE_SIZE: "100"
          SCRY_TASK_STUCK_TASK_AGE_MINUTES: "30"

  lint:
    name: Lint
    runs-on: ubuntu-latest
    needs: pre-flight
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }} # Using centralized version
          cache: true
      - name: Run golangci-lint
        uses: golangci/golangci-lint-action@v8
        with:
          version: v2.1.1
          args: --verbose --build-tags=test_without_external_deps

  test-unit:
    name: Unit Test - ${{ matrix.package }}
    runs-on: ubuntu-latest
    needs: pre-flight
    strategy:
      fail-fast: false # Allow other jobs to continue if one fails
      matrix:
        package:
          - cmd/server
          - internal/api
          - internal/api/middleware
          - internal/api/shared
          - internal/ciutil
          - internal/config
          - internal/domain
          - internal/domain/srs
          - internal/events
          - internal/generation
          - internal/platform/gemini
          - internal/platform/logger
          - internal/platform/postgres
          - internal/redact
          - internal/service
          - internal/service/auth
          - internal/service/card_review
          - internal/store
          - internal/task
          - internal/testutils
          - infrastructure
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true
      - name: Install required tools and libraries for CGo
        run: |
          sudo apt-get update
          sudo apt-get install -y jq gcc libpq-dev

      - name: Build main application
        run: go build ./cmd/server

      - name: Run unit tests
        run: |
          PACKAGE_NAME=$(echo "${{ matrix.package }}" | tr '/' '-')
          GOTEST_DEBUG=1 go test -v -json -race -coverprofile=coverage-unit-${PACKAGE_NAME}.out -tags=test_without_external_deps,exported_core_functions ./${{ matrix.package }}/... | tee test-results-unit-${PACKAGE_NAME}.json
          TEST_EXIT_CODE=${PIPESTATUS[0]}

          # Concise error reporting for test failures
          if [ -f test-results-unit-${PACKAGE_NAME}.json ]; then
            FAILURE_COUNT=$(grep -c '"Action":"fail"' test-results-unit-${PACKAGE_NAME}.json || echo "0")
            if [ "$FAILURE_COUNT" -gt "0" ]; then
              echo "::error::Found $FAILURE_COUNT unit test failures in package ${{ matrix.package }}"
              echo "=== Failed Tests ==="
              grep '"Action":"fail"' test-results-unit-${PACKAGE_NAME}.json | \
                jq -r '"- " + (.Package // "unknown") + ": " + (.Test // "package failure")' 2>/dev/null || \
                grep '"Action":"fail"' test-results-unit-${PACKAGE_NAME}.json | head -5
            fi
            echo "$TEST_EXIT_CODE" > "test-exit-code-unit-${PACKAGE_NAME}.txt"
          fi
        env:
          # Enable CGo
          CGO_ENABLED: 1
          # Project root variable
          SCRY_PROJECT_ROOT: ${{ github.workspace }}
          # Unit test environment
          SCRY_AUTH_JWT_SECRET: ci-test-jwt-secret-32-characters-long
          SCRY_AUTH_BCRYPT_COST: "10"
          SCRY_LLM_GEMINI_API_KEY: ci-test-gemini-key
          SCRY_LLM_MODEL_NAME: gemini-2.0-flash
          SCRY_LLM_PROMPT_TEMPLATE_PATH: prompts/flashcard_template.txt
          SCRY_SERVER_LOG_LEVEL: info

      - name: Check unit test coverage
        run: |
          PACKAGE_NAME=$(echo "${{ matrix.package }}" | tr '/' '-')
          if [ -f "coverage-unit-${PACKAGE_NAME}.out" ]; then
            echo "Running: go tool cover -func=coverage-unit-${PACKAGE_NAME}.out"
            go tool cover -func=coverage-unit-${PACKAGE_NAME}.out

            # Extract coverage percentage for this package
            total_coverage=$(go tool cover -func=coverage-unit-${PACKAGE_NAME}.out | grep total: | awk '{print $3}' | sed 's/%//')
            echo "Unit test coverage for ${{ matrix.package }}: $total_coverage"

            # Check if this package has a specific threshold in the config with error handling
            if [[ -f "coverage-thresholds.json" ]]; then
              # Check if this package should be excluded with error handling
              if command -v jq >/dev/null 2>&1; then
                is_excluded=$(jq -r --arg pkg "${{ matrix.package }}" '.excluded_packages[] | select(. == $pkg) | length > 0' coverage-thresholds.json 2>/dev/null)
                if [[ "$is_excluded" == "true" ]]; then
                  echo "Package ${{ matrix.package }} is excluded from coverage requirements"
                  exit 0
                fi

                # Get package-specific threshold or use default
                threshold=$(jq -r --arg pkg "${{ matrix.package }}" '.package_thresholds[$pkg] // .default_threshold' coverage-thresholds.json 2>/dev/null)
                if [[ -z "$threshold" || "$threshold" == "null" ]]; then
                  echo "::warning::Could not read threshold from coverage-thresholds.json, using default of 50%"
                  threshold=50
                fi
                echo "Required coverage threshold for ${{ matrix.package }}: $threshold%"
              else
                echo "::warning::jq not available, using default coverage threshold of 50%"
                threshold=50
              fi

              # Special handling for packages with 0% threshold - they legitimately have no unit tests
              if [[ "$threshold" == "0" ]]; then
                echo "::notice::Package ${{ matrix.package }} has 0% threshold - no unit test coverage requirement"
                exit 0
              fi

              # Convert to integer (remove decimal part) for comparison
              coverage_int=$(echo $total_coverage | cut -d. -f1)
              if [[ $coverage_int -lt $threshold ]]; then
                echo "::error::Package ${{ matrix.package }} has unit test coverage $total_coverage% which is below the required threshold of $threshold%"
                exit 1
              else
                echo "::notice::Package ${{ matrix.package }} meets unit test coverage requirement: $total_coverage% (threshold: $threshold%)"
              fi
            else
              echo "::warning::coverage-thresholds.json not found, skipping package-specific threshold check"
            fi
          else
            echo "::warning::No unit test coverage file found for ${{ matrix.package }}"
          fi

      # Upload unit test artifacts
      - name: Create sanitized package name
        id: sanitize
        run: |
          # Replace forward slashes with hyphens in package name
          SANITIZED_PACKAGE=$(echo "${{ matrix.package }}" | tr '/' '-')
          echo "sanitized_package=$SANITIZED_PACKAGE" >> $GITHUB_OUTPUT
          echo "Sanitized package name: $SANITIZED_PACKAGE"

      - name: Upload unit test results
        uses: actions/upload-artifact@v4
        if: always() # Upload even if tests fail
        with:
          name: unit-test-results-${{ steps.sanitize.outputs.sanitized_package }}-${{ runner.os }}-${{ github.run_id }}
          path: |
            test-results-unit-*.json
            coverage-unit-*.out
            test-exit-code-unit-*.txt
          retention-days: 30

  test-integration:
    name: Integration Test - ${{ matrix.package }}
    runs-on: ubuntu-latest
    needs: pre-flight
    strategy:
      fail-fast: false # Allow other jobs to continue if one fails
      matrix:
        package:
          - cmd/server
          - internal/api
          - internal/api/middleware
          - internal/api/shared
          - internal/ciutil
          - internal/config
          - internal/domain
          - internal/domain/srs
          - internal/events
          - internal/generation
          - internal/platform/gemini
          - internal/platform/logger
          - internal/platform/postgres
          - internal/redact
          - internal/service
          - internal/service/auth
          - internal/service/card_review
          - internal/store
          - internal/task
          - internal/testutils
          - infrastructure
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: scry_test
        ports:
          - 5432:5432
        # Health check to ensure PostgreSQL is ready before running tests
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true
      - name: Install required tools and libraries for CGo
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client jq gcc libpq-dev

      - name: Build main application
        run: go build ./cmd/server

      - name: Migration Smoke Test
        run: go run ./cmd/server -migrate=status
        env:
          # Enable CGo
          CGO_ENABLED: 1
          # Database environment
          DATABASE_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          SCRY_TEST_DB_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          SCRY_DATABASE_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          # Project root variable
          SCRY_PROJECT_ROOT: ${{ github.workspace }}
          # Environment variables
          SCRY_AUTH_JWT_SECRET: ci-test-jwt-secret-32-characters-long
          SCRY_LLM_GEMINI_API_KEY: ci-test-gemini-key
          SCRY_LLM_PROMPT_TEMPLATE_PATH: prompts/flashcard_template.txt

      - name: Verify database connectivity
        run: |
          chmod +x ./scripts/wait-for-db.sh
          ./scripts/wait-for-db.sh --attempts 20 --sleep 3 --timeout 90
        env:
          DATABASE_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          SCRY_TEST_DB_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          SCRY_DATABASE_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable

      - name: Reset and prepare database
        run: |
          chmod +x ./scripts/reset-test-db.sh
          ./scripts/reset-test-db.sh
          go run ./cmd/server -migrate=up
          go run ./cmd/server -validate-migrations -verbose
        env:
          # Enable CGo
          CGO_ENABLED: 1
          # Database environment
          DATABASE_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          SCRY_TEST_DB_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          SCRY_DATABASE_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          # Project root
          SCRY_PROJECT_ROOT: ${{ github.workspace }}

          # Configuration environment
          SCRY_AUTH_JWT_SECRET: ci-test-jwt-secret-32-characters-long
          SCRY_AUTH_BCRYPT_COST: "10"
          SCRY_AUTH_TOKEN_LIFETIME_MINUTES: "60"
          SCRY_AUTH_REFRESH_TOKEN_LIFETIME_MINUTES: "10080"
          SCRY_LLM_GEMINI_API_KEY: ci-test-gemini-key
          SCRY_LLM_MODEL_NAME: gemini-2.0-flash
          SCRY_LLM_PROMPT_TEMPLATE_PATH: prompts/flashcard_template.txt
          SCRY_LLM_MAX_RETRIES: "3"
          SCRY_LLM_RETRY_DELAY_SECONDS: "2"
          SCRY_SERVER_PORT: "8080"
          SCRY_SERVER_LOG_LEVEL: info
          SCRY_TASK_WORKER_COUNT: "2"
          SCRY_TASK_QUEUE_SIZE: "100"
          SCRY_TASK_STUCK_TASK_AGE_MINUTES: "30"

      - name: Validate database connection for tests
        run: |
          echo "Validating database connection..."
          echo 'package main; import ("database/sql"; _ "github.com/jackc/pgx/v5/stdlib"; "os"); func main() { db, err := sql.Open("pgx", os.Getenv("DATABASE_URL")); if err != nil { panic(err) }; defer db.Close(); if err := db.Ping(); err != nil { panic(err) }; println("âœ“ Database connection validated") }' > dbval.go
          go run dbval.go && rm dbval.go
        env:
          # Enable CGo
          CGO_ENABLED: 1
          # Database environment
          DATABASE_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          SCRY_TEST_DB_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          SCRY_DATABASE_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          # Project root variable
          SCRY_PROJECT_ROOT: ${{ github.workspace }}
          # Configuration environment
          SCRY_AUTH_JWT_SECRET: ci-test-jwt-secret-32-characters-long
          SCRY_AUTH_BCRYPT_COST: "10"
          SCRY_AUTH_TOKEN_LIFETIME_MINUTES: "60"
          SCRY_AUTH_REFRESH_TOKEN_LIFETIME_MINUTES: "10080"
          SCRY_LLM_GEMINI_API_KEY: ci-test-gemini-key
          SCRY_LLM_MODEL_NAME: gemini-2.0-flash
          SCRY_LLM_PROMPT_TEMPLATE_PATH: prompts/flashcard_template.txt
          SCRY_LLM_MAX_RETRIES: "3"
          SCRY_LLM_RETRY_DELAY_SECONDS: "2"
          SCRY_SERVER_PORT: "8080"
          SCRY_SERVER_LOG_LEVEL: debug
          SCRY_TASK_WORKER_COUNT: "2"
          SCRY_TASK_QUEUE_SIZE: "100"
          SCRY_TASK_STUCK_TASK_AGE_MINUTES: "30"

      - name: Run tests
        run: |
          ./scripts/reset-test-db.sh
          go run ./cmd/server -migrate=up
          go run ./cmd/server -validate-migrations
          PACKAGE_NAME=$(echo "${{ matrix.package }}" | tr '/' '-')
          GOTEST_DEBUG=1 go test -v -json -race -coverprofile=coverage-integration-${PACKAGE_NAME}.out -tags=integration,exported_core_functions ./${{ matrix.package }}/... | tee test-results-integration-${PACKAGE_NAME}.json
          TEST_EXIT_CODE=${PIPESTATUS[0]}

          # Concise error reporting for integration test failures
          if [ -f test-results-integration-${PACKAGE_NAME}.json ]; then
            FAILURE_COUNT=$(grep -c '"Action":"fail"' test-results-integration-${PACKAGE_NAME}.json || echo "0")
            if [ "$FAILURE_COUNT" -gt "0" ]; then
              echo "::error::Found $FAILURE_COUNT integration test failures in package ${{ matrix.package }}"
              echo "=== Failed Tests ==="
              grep '"Action":"fail"' test-results-integration-${PACKAGE_NAME}.json | \
                jq -r '"- " + (.Package // "unknown") + ": " + (.Test // "package failure")' 2>/dev/null || \
                grep '"Action":"fail"' test-results-integration-${PACKAGE_NAME}.json | head -5
            fi
            echo "$TEST_EXIT_CODE" > "test-exit-code-integration-${PACKAGE_NAME}.txt"
          fi
        env:
          # Enable CGo
          CGO_ENABLED: 1
          # Database environment
          DATABASE_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          SCRY_TEST_DB_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          SCRY_DATABASE_URL: postgres://postgres:postgres@localhost:5432/scry_test?sslmode=disable
          # Project root
          SCRY_PROJECT_ROOT: ${{ github.workspace }}

          # Configuration environment
          SCRY_AUTH_JWT_SECRET: ci-test-jwt-secret-32-characters-long
          SCRY_AUTH_BCRYPT_COST: "10"
          SCRY_AUTH_TOKEN_LIFETIME_MINUTES: "60"
          SCRY_AUTH_REFRESH_TOKEN_LIFETIME_MINUTES: "10080"
          SCRY_LLM_GEMINI_API_KEY: ci-test-gemini-key
          SCRY_LLM_MODEL_NAME: gemini-2.0-flash
          SCRY_LLM_PROMPT_TEMPLATE_PATH: prompts/flashcard_template.txt
          SCRY_LLM_MAX_RETRIES: "3"
          SCRY_LLM_RETRY_DELAY_SECONDS: "2"
          SCRY_SERVER_PORT: "8080"
          SCRY_SERVER_LOG_LEVEL: debug # Set to debug for more detailed logs
          GOLOG_LOG_LEVEL: debug
          GO_TEST_VERBOSE: "1"
          GO_TEST_LOG_LEVEL: debug
          SCRY_TASK_WORKER_COUNT: "2"
          SCRY_TASK_QUEUE_SIZE: "100"
          SCRY_TASK_STUCK_TASK_AGE_MINUTES: "30"
      - name: Check integration test coverage
        run: |
          PACKAGE_NAME=$(echo "${{ matrix.package }}" | tr '/' '-')
          if [ -f "coverage-integration-${PACKAGE_NAME}.out" ]; then
            echo "Running: go tool cover -func=coverage-integration-${PACKAGE_NAME}.out"
            go tool cover -func=coverage-integration-${PACKAGE_NAME}.out

            # Extract coverage percentage for this package
            total_coverage=$(go tool cover -func=coverage-integration-${PACKAGE_NAME}.out | grep total: | awk '{print $3}' | sed 's/%//')
            echo "Integration test coverage for ${{ matrix.package }}: $total_coverage"

            # Check if this package has a specific threshold in the config with error handling
            if [[ -f "coverage-thresholds.json" ]]; then
              # Check if this package should be excluded with error handling
              if command -v jq >/dev/null 2>&1; then
                is_excluded=$(jq -r --arg pkg "${{ matrix.package }}" '.excluded_packages[] | select(. == $pkg) | length > 0' coverage-thresholds.json 2>/dev/null)
                if [[ "$is_excluded" == "true" ]]; then
                  echo "Package ${{ matrix.package }} is excluded from coverage requirements"
                  exit 0
                fi

                # Get package-specific threshold or use default
                threshold=$(jq -r --arg pkg "${{ matrix.package }}" '.package_thresholds[$pkg] // .default_threshold' coverage-thresholds.json 2>/dev/null)
                if [[ -z "$threshold" || "$threshold" == "null" ]]; then
                  echo "::warning::Could not read threshold from coverage-thresholds.json, using default of 50%"
                  threshold=50
                fi
                echo "Required coverage threshold for ${{ matrix.package }}: $threshold%"

                # Special handling for packages with 0% threshold - they legitimately have no integration tests
                if [[ "$threshold" == "0" ]]; then
                  echo "::notice::Package ${{ matrix.package }} has 0% threshold - no integration tests required"
                  exit 0
                fi
              else
                echo "::warning::jq not available, using default coverage threshold of 50%"
                threshold=50
              fi

              # Convert to integer (remove decimal part) for comparison
              coverage_int=$(echo $total_coverage | cut -d. -f1)
              if [[ $coverage_int -lt $threshold ]]; then
                echo "::error::Package ${{ matrix.package }} has integration test coverage $total_coverage% which is below the required threshold of $threshold%"
                exit 1
              else
                echo "::notice::Package ${{ matrix.package }} meets integration test coverage requirement: $total_coverage% (threshold: $threshold%)"
              fi
            else
              echo "::warning::coverage-thresholds.json not found, skipping package-specific threshold check"
            fi
          else
            echo "::warning::No integration test coverage file found for ${{ matrix.package }}"
            # Check if this package has 0% threshold (no integration tests expected)
            if [[ -f "coverage-thresholds.json" ]]; then
              if command -v jq >/dev/null 2>&1; then
                threshold=$(jq -r --arg pkg "${{ matrix.package }}" '.package_thresholds[$pkg] // .default_threshold' coverage-thresholds.json 2>/dev/null)
                if [[ "$threshold" == "0" ]]; then
                  echo "::notice::Package ${{ matrix.package }} has 0% threshold - no integration test coverage file expected"
                  exit 0
                fi
              fi
            fi
            echo "::error::No integration test coverage file found for ${{ matrix.package }} but coverage is required"
            exit 1
          fi
      # Upload test artifacts with extended diagnostics
      # Create sanitized package name for artifact naming (replace / with -)
      - name: Create sanitized package name
        id: sanitize
        run: |
          # Replace forward slashes with hyphens in package name
          SANITIZED_PACKAGE=$(echo "${{ matrix.package }}" | tr '/' '-')
          echo "sanitized_package=$SANITIZED_PACKAGE" >> $GITHUB_OUTPUT
          echo "Sanitized package name: $SANITIZED_PACKAGE"

      - name: Upload integration test results and diagnostics
        uses: actions/upload-artifact@v4
        if: always() # Upload even if tests fail
        with:
          # Use sanitized package name to avoid GitHub Actions artifact naming restrictions
          name: integration-test-results-${{ steps.sanitize.outputs.sanitized_package }}-${{ runner.os }}-${{ github.run_id }}
          path: |
            test-results-integration-*.json
            coverage-integration-*.out
            test-exit-code-integration-*.txt
          retention-days: 30

      # Simplified diagnostics for failed tests
      - name: Upload failure diagnostics
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: integration-test-diagnostics-${{ steps.sanitize.outputs.sanitized_package }}-${{ runner.os }}-${{ github.run_id }}
          path: test-results-integration-*.json
          retention-days: 30

      # Add job summary with artifact information
      - name: Create job summary with artifact information
        if: always() # Run this step regardless of test outcome
        run: |
          echo "## Test Summary for ${{ matrix.package }}" >> $GITHUB_STEP_SUMMARY

          # Add status badge
          if [ "${{ job.status }}" == "success" ]; then
            echo "âœ… **Status**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **Status**: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          # Add artifact information
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“Š [Test Results Artifact](${GITHUB_SERVER_URL}/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID})" >> $GITHUB_STEP_SUMMARY

          # Add additional information for failed tests
          if [ "${{ job.status }}" != "success" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Diagnostic Information" >> $GITHUB_STEP_SUMMARY
            echo "ðŸ“‹ [Failure Diagnostics Artifact](${GITHUB_SERVER_URL}/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID})" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "â„¹ï¸ **To download and view artifacts:**" >> $GITHUB_STEP_SUMMARY
            echo "1. Go to the Actions tab in the repository" >> $GITHUB_STEP_SUMMARY
            echo "2. Select this workflow run" >> $GITHUB_STEP_SUMMARY
            echo "3. Scroll down to the Artifacts section" >> $GITHUB_STEP_SUMMARY
            echo "4. Download the relevant artifact zip file" >> $GITHUB_STEP_SUMMARY
          fi

  coverage-check:
    name: Overall Coverage Check
    runs-on: ubuntu-latest
    needs: [test-unit, test-integration]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true

      - name: Install jq
        run: |
          sudo apt-get update
          sudo apt-get install -y jq

      - name: Download all coverage reports
        uses: actions/download-artifact@v4
        with:
          # This pattern will match all test result artifacts (both unit and integration) with sanitized names
          pattern: "*-test-results-*"
          path: coverage-reports/

      - name: Merge coverage reports
        run: |
          echo "Merging coverage reports from all packages..."
          # Create a temporary directory for all coverage files
          mkdir -p merged-coverage

          # Find all coverage files and copy them to the temp directory
          find coverage-reports -name "*.out" -exec cp {} merged-coverage/ \;

          # Use go tool to merge all coverage files
          echo "Coverage files found:"
          ls -la merged-coverage/

          # Create a merged coverage report
          echo "mode: set" > merged-coverage.out
          tail -q -n +2 merged-coverage/*.out >> merged-coverage.out || echo "No coverage files found to merge"

          # Display merged coverage
          echo "Merged coverage report:"
          go tool cover -func=merged-coverage.out

          # Check overall coverage threshold
          total_coverage=$(go tool cover -func=merged-coverage.out | grep total: | awk '{print $3}' | sed 's/%//')
          echo "Total project coverage: $total_coverage"

          # Get overall threshold from configuration with error handling
          if [[ -f "coverage-thresholds.json" ]]; then
            if command -v jq >/dev/null 2>&1; then
              overall_threshold=$(jq -r '.default_threshold' coverage-thresholds.json 2>/dev/null)
              if [[ -z "$overall_threshold" || "$overall_threshold" == "null" ]]; then
                echo "::warning::Could not read default_threshold from coverage-thresholds.json, using default of 70%"
                overall_threshold=70
              fi
              echo "Required overall coverage threshold: $overall_threshold%"
            else
              echo "::warning::jq not available, using default threshold of 70%"
              overall_threshold=70
            fi
          else
            echo "::warning::coverage-thresholds.json not found, using default threshold of 70%"
            overall_threshold=70
          fi

          # Convert to integer (remove decimal part) for comparison
          coverage_int=$(echo $total_coverage | cut -d. -f1)
          if [ "$coverage_int" -lt "$overall_threshold" ]; then
            echo "::error::Overall code coverage is $total_coverage% which is below the required threshold of $overall_threshold%"
            exit 1
          else
            echo "::notice::Project meets overall coverage requirement: $total_coverage% (threshold: $overall_threshold%)"
          fi

      - name: Upload merged coverage
        uses: actions/upload-artifact@v4
        with:
          name: merged-coverage-${{ runner.os }}-${{ github.run_id }}
          path: merged-coverage.out
          retention-days: 30

  # Add a summary of artifacts for the entire workflow
  artifact-summary:
    name: Artifact Availability Summary
    runs-on: ubuntu-latest
    if: always() # Always run this job
    needs: [test-unit, test-integration, coverage-check, build]
    steps:
      - name: Summarize artifact availability
        run: |
          echo "## ðŸ“Š CI Artifacts Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The following artifacts are available for this workflow run:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Standard Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- Test results for each package" >> $GITHUB_STEP_SUMMARY
          echo "- Coverage reports" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "### For Failed Tests" >> $GITHUB_STEP_SUMMARY
          echo "If tests failed, additional diagnostic information is available in:" >> $GITHUB_STEP_SUMMARY
          echo "- Test diagnostics artifacts (one per failed package)" >> $GITHUB_STEP_SUMMARY
          echo "- Full test logs with error details" >> $GITHUB_STEP_SUMMARY
          echo "- System and environment information" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "### How to Access Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "1. Go to the **Actions** tab in the repository" >> $GITHUB_STEP_SUMMARY
          echo "2. Select this workflow run: [Run #${{ github.run_id }}](${GITHUB_SERVER_URL}/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID})" >> $GITHUB_STEP_SUMMARY
          echo "3. Scroll down to the **Artifacts** section" >> $GITHUB_STEP_SUMMARY
          echo "4. Download the relevant artifact zip file" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Add notice about artifacts
          echo "::notice::ðŸ“‹ Artifacts Summary Available: All test results and diagnostics for this workflow run can be viewed in the 'Artifact Availability Summary' job."

  build:
    name: Build
    runs-on: ubuntu-latest
    needs: pre-flight
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true
      - name: Build application
        run: |
          echo "Building application..."
          echo "Running: go build -v ./cmd/server/..."
          go build -v ./cmd/server/...
          echo "Build completed successfully"

  # Optional job that runs tests with the real Gemini API (without the test_without_external_deps build tag)
  # This job is triggered manually via workflow_dispatch or on a weekly schedule
  #
  # PURPOSE:
  # - Verify real-world integration with the Gemini API
  # - Catch breaking changes in the API that mocks might miss
  # - Ensure prompt templates work as expected with the actual API
  #
  # COSTS & CONSIDERATIONS:
  # - Each test run will make multiple API calls that may incur costs
  # - API calls may be subject to rate limits (adjust test timeout if needed)
  # - Tests might become flaky due to API availability or changes
  # - Weekly scheduled runs help catch issues proactively
  #
  # SECURITY:
  # - API key is stored as a GitHub Secret (GEMINI_API_KEY)
  # - The job will fail if the secret is not available
  # - No API key information should appear in logs
  test-gemini-integration:
    name: Test Gemini Integration
    # Run only when explicitly requested via workflow_dispatch or weekly schedule
    if: |
      github.event_name == 'workflow_dispatch' && inputs.run-gemini-tests ||
      github.event_name == 'schedule'
    runs-on: ubuntu-latest
    # Set a timeout to prevent excessive usage in case of API issues
    timeout-minutes: 15
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true

      # Check for required secret before continuing
      - name: Verify Gemini API key is available
        run: |
          if [ -z "${{ secrets.GEMINI_API_KEY }}" ]; then
            echo "::error::GEMINI_API_KEY secret is not configured."
            echo "::error::Please add the GEMINI_API_KEY secret in your repository settings."
            echo "::error::This is required for running tests with the real Gemini API."
            exit 1
          else
            echo "::notice::GEMINI_API_KEY secret is available. Proceeding with tests."
          fi

      # Configure any specific test environment variables
      - name: Configure test environment
        run: |
          echo "::notice::Preparing to run Gemini integration tests with actual API"
          echo "::notice::Tests will be run without the test_without_external_deps build tag"
          echo "::notice::Timeout set to 5 minutes to account for API latency and potential retries"

      # Install required libraries for CGo
      - name: Install required tools and libraries for CGo
        run: |
          echo "Installing C compiler and development libraries for CGo..."
          sudo apt-get update
          sudo apt-get install -y gcc libpq-dev

          # Verify installations
          echo "Verifying installed libraries:"
          echo "GCC version:"
          gcc --version
          echo "libpq availability:"
          pkg-config --libs libpq || echo "libpq available (pkg-config not showing details)"
          echo "Listing PostgreSQL dev files:"
          ls -la /usr/include/postgresql/ || echo "PostgreSQL headers not found in default location"

      # Run tests specifically for the Gemini package without the test_without_external_deps tag
      - name: Run Gemini integration tests
        id: tests
        run: |
          echo "::group::Running Gemini API integration tests"
          echo "Running tests against real Gemini API at $(date)"

          # Log environment info for better diagnostics
          echo "=== Test Environment Information ==="
          echo "Go version: $(go version)"
          echo "CGO enabled: CGO_ENABLED=$CGO_ENABLED"
          echo "Test directory: $(pwd)"
          echo "Test timeout: $GO_TEST_TIMEOUT"
          echo "=================================="


          GOTEST_DEBUG=1 GODEBUG=gctrace=0 go test -v -json -timeout 5m ./internal/platform/gemini/... | tee gemini-test-results.json

          TEST_EXIT_CODE=${PIPESTATUS[0]}

          # Concise error reporting for Gemini test failures
          if [ -f gemini-test-results.json ]; then
            FAILURE_COUNT=$(grep -c '"Action":"fail"' gemini-test-results.json || echo "0")
            if [ "$FAILURE_COUNT" -gt "0" ]; then
              echo "::error::Found $FAILURE_COUNT test failures in Gemini API tests"
              echo "=== Failed Tests ==="
              grep '"Action":"fail"' gemini-test-results.json | \
                jq -r '"- " + (.Package // "unknown") + ": " + (.Test // "package failure")' 2>/dev/null || \
                grep '"Action":"fail"' gemini-test-results.json | head -5
            else
              echo "::notice::All Gemini API tests passed successfully"
            fi
          else
            echo "::warning::No Gemini API test results file found"
          fi
        env:
          # Enable CGo
          CGO_ENABLED: 1
          GO_TEST_VERBOSE: "1"
          GOTEST_DEBUG: "1"
          SCRY_SERVER_LOG_LEVEL: debug
          GOLOG_LOG_LEVEL: debug
          GO_TEST_LOG_LEVEL: debug
          # API key and timeout
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          GO_TEST_TIMEOUT: 5m

      # Upload test results if any exist with enhanced diagnostics
      - name: Upload Gemini test results
        uses: actions/upload-artifact@v4
        if: always() # Upload even if tests fail
        with:
          name: gemini-test-results-${{ runner.os }}-${{ github.run_id }}
          path: |
            gemini-test-results.json
          retention-days: 30

      # For failed Gemini tests, gather and upload additional diagnostics
      - name: Gather diagnostics for failed Gemini tests
        if: failure() # Only run this when tests fail
        run: |
          echo "::group::Additional Diagnostics for Gemini API Tests"

          # Create diagnostics directory
          mkdir -p gemini-test-diagnostics

          # System information
          echo "System information:" > gemini-test-diagnostics/system-info.txt
          uname -a >> gemini-test-diagnostics/system-info.txt
          free -h >> gemini-test-diagnostics/system-info.txt 2>/dev/null || echo "free command not available" >> gemini-test-diagnostics/system-info.txt
          df -h >> gemini-test-diagnostics/system-info.txt 2>/dev/null || echo "df command not available" >> gemini-test-diagnostics/system-info.txt

          # Go environment
          echo "Go environment:" > gemini-test-diagnostics/go-env.txt
          go env >> gemini-test-diagnostics/go-env.txt
          go version >> gemini-test-diagnostics/go-env.txt

          # Save detailed test information
          if [ -f gemini-test-results.json ]; then
            # Test failure details with robust error handling
            echo "Test failure details:" > gemini-test-diagnostics/test-failures.txt
            # Extract and format test failures with proper escaping
            if command -v jq >/dev/null 2>&1; then
              grep '"Action":"fail"' gemini-test-results.json | \
                jq -r 'select(.Test != null) | "- Test: " + (.Test // "unknown") + "\n  Package: " + (.Package // "unknown") + "\n  Output: " + (.Output // "no output") + "\n---"' \
                >> gemini-test-diagnostics/test-failures.txt 2>/dev/null || {
                echo "jq parsing failed for failure details, using fallback method" >> gemini-test-diagnostics/test-failures.txt
                grep '"Action":"fail"' gemini-test-results.json | head -10 >> gemini-test-diagnostics/test-failures.txt
              }
            else
              echo "jq not available for detailed parsing" >> gemini-test-diagnostics/test-failures.txt
              grep '"Action":"fail"' gemini-test-results.json | head -10 >> gemini-test-diagnostics/test-failures.txt
            fi

            # Save full test output for reference
            echo "Full test results JSON (for debugging):" > gemini-test-diagnostics/full-test-results.txt
            cat gemini-test-results.json >> gemini-test-diagnostics/full-test-results.txt

            # Test statistics
            echo "Test statistics:" > gemini-test-diagnostics/test-stats.txt
            PASSED_COUNT=$(grep -c '"Action":"pass"' gemini-test-results.json || echo "0")
            FAILED_COUNT=$(grep -c '"Action":"fail"' gemini-test-results.json || echo "0")
            SKIP_COUNT=$(grep -c '"Action":"skip"' gemini-test-results.json || echo "0")
            echo "- Tests passed: $PASSED_COUNT" >> gemini-test-diagnostics/test-stats.txt
            echo "- Tests failed: $FAILED_COUNT" >> gemini-test-diagnostics/test-stats.txt
            echo "- Tests skipped: $SKIP_COUNT" >> gemini-test-diagnostics/test-stats.txt

            # Extract API errors to a separate file with robust error handling
            echo "API Errors:" > gemini-test-diagnostics/api-errors.txt
            if command -v jq >/dev/null 2>&1; then
              grep '"Action":"fail"' gemini-test-results.json | \
                jq -r 'select(.Output != null) | .Output' 2>/dev/null | \
                grep -E "Error:|Failed|API|Status Code:|response body:" >> gemini-test-diagnostics/api-errors.txt || \
                echo "No specific API errors found" >> gemini-test-diagnostics/api-errors.txt
            else
              grep '"Action":"fail"' gemini-test-results.json | \
                grep -E "Error:|Failed|API|Status Code:|response body:" >> gemini-test-diagnostics/api-errors.txt || \
                echo "No specific API errors found (jq not available)" >> gemini-test-diagnostics/api-errors.txt
            fi

            # Copy test results file
            cp gemini-test-results.json gemini-test-diagnostics/
          else
            echo "No test results file found" > gemini-test-diagnostics/test-info.txt
          fi

          # Environment variables (redacted)
          echo "Environment variables (redacted):" > gemini-test-diagnostics/env-vars.txt
          env | grep -v -E "SECRET|KEY|TOKEN|PASSWORD" | sort >> gemini-test-diagnostics/env-vars.txt

          # Internet connectivity check
          echo "Internet connectivity check:" > gemini-test-diagnostics/connectivity.txt
          curl -s --head https://generativelanguage.googleapis.com/ | head -n 1 >> gemini-test-diagnostics/connectivity.txt 2>/dev/null || echo "Could not connect to Gemini API" >> gemini-test-diagnostics/connectivity.txt


      # Upload diagnostics for failed tests
      - name: Upload Gemini failure diagnostics
        uses: actions/upload-artifact@v4
        if: failure() # Only upload when tests fail
        with:
          # Using a safe name without forward slashes
          name: gemini-test-diagnostics-${{ runner.os }}-${{ github.run_id }}
          path: gemini-test-diagnostics
          retention-days: 30

      # Add a comprehensive summary of the test run with enhanced details
      - name: Gemini integration test summary
        if: always() # Run even if tests fail
        run: |
          echo "::group::Gemini API Integration Test Summary"

          # Create a summary report file
          SUMMARY_FILE="gemini-test-summary.txt"
          echo "=== GEMINI API INTEGRATION TEST SUMMARY ===" > $SUMMARY_FILE
          echo "Date: $(date)" >> $SUMMARY_FILE
          echo "Test result: ${{ steps.tests.outcome }}" >> $SUMMARY_FILE
          echo "" >> $SUMMARY_FILE

          if [ "${{ steps.tests.outcome }}" == "success" ]; then
            echo "::notice::âœ… Gemini API integration tests completed successfully at $(date)"
            echo "Test Status: SUCCESS" >> $SUMMARY_FILE

            # Count passed tests
            if [ -f gemini-test-results.json ]; then
              PASSED_COUNT=$(grep -c '"Action":"pass"' gemini-test-results.json || echo "0")
              echo "Total tests passed: $PASSED_COUNT" >> $SUMMARY_FILE
            fi
          else
            echo "::warning::âš ï¸ Gemini API integration tests failed at $(date)"
            echo "::warning::This could be due to API changes, rate limits, or temporary service issues."
            echo "Test Status: FAILED" >> $SUMMARY_FILE
            echo "Possible causes:" >> $SUMMARY_FILE
            echo "- API changes" >> $SUMMARY_FILE
            echo "- Rate limits" >> $SUMMARY_FILE
            echo "- Temporary service issues" >> $SUMMARY_FILE
            echo "- Network connectivity problems" >> $SUMMARY_FILE
            echo "" >> $SUMMARY_FILE

            # Extract and format test failures if any exist
            if [ -f gemini-test-results.json ]; then
              echo "Failed tests:" >> $SUMMARY_FILE
              PASSED_COUNT=$(grep -c '"Action":"pass"' gemini-test-results.json || echo "0")
              FAILED_COUNT=$(grep -c '"Action":"fail"' gemini-test-results.json || echo "0")
              SKIP_COUNT=$(grep -c '"Action":"skip"' gemini-test-results.json || echo "0")

              echo "Test statistics:" >> $SUMMARY_FILE
              echo "- Passed: $PASSED_COUNT" >> $SUMMARY_FILE
              echo "- Failed: $FAILED_COUNT" >> $SUMMARY_FILE
              echo "- Skipped: $SKIP_COUNT" >> $SUMMARY_FILE
              echo "" >> $SUMMARY_FILE

              echo "Failed test details:" >> $SUMMARY_FILE
              if command -v jq >/dev/null 2>&1; then
                grep '"Action":"fail"' gemini-test-results.json | \
                  jq -r '"- Package: " + (.Package // "unknown") + ", Test: " + (.Test // "package failure")' \
                  >> $SUMMARY_FILE 2>/dev/null || \
                  echo "Could not extract detailed failure information" >> $SUMMARY_FILE
              else
                echo "Could not extract detailed failure information (jq not available)" >> $SUMMARY_FILE
              fi

              echo "" >> $SUMMARY_FILE
              echo "Error summary:" >> $SUMMARY_FILE
              if command -v jq >/dev/null 2>&1; then
                grep '"Action":"fail"' gemini-test-results.json | \
                  jq -r 'select(.Output != null) | .Output' 2>/dev/null | \
                  grep -E "Error:|API error:|Status Code:|response body:" >> $SUMMARY_FILE || \
                  echo "No specific API error details found" >> $SUMMARY_FILE
              else
                grep '"Action":"fail"' gemini-test-results.json | \
                  grep -E "Error:|API error:|Status Code:|response body:" >> $SUMMARY_FILE || \
                  echo "No specific API error details found (jq not available)" >> $SUMMARY_FILE
              fi
            fi
          fi

          echo "" >> $SUMMARY_FILE
          echo "IMPORTANT NOTES:" >> $SUMMARY_FILE
          echo "- These tests run with the actual Gemini API and may be affected by external factors" >> $SUMMARY_FILE
          echo "- Consider checking the Gemini API status if tests fail unexpectedly" >> $SUMMARY_FILE
          echo "- The failure diagnostics artifact contains additional information" >> $SUMMARY_FILE
          echo "====================================================" >> $SUMMARY_FILE
          # Output the summary to the log
          cat $SUMMARY_FILE
          # Save the summary file for artifacts
          mkdir -p gemini-test-diagnostics
          cp $SUMMARY_FILE gemini-test-diagnostics/
          # Always output these notices outside the group
          echo "::notice::These tests run with the actual Gemini API and may be affected by external factors."
          echo "::notice::Consider checking the Gemini API status if tests fail unexpectedly."
          # Add a prominent notice about diagnostics artifacts
          if [ "${{ steps.tests.outcome }}" != "success" ]; then
            echo "::notice::ðŸ“Š Detailed diagnostics are available in the workflow artifacts."
          fi
